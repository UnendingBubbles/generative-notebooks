{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UnenBubb-ruDALLE-generation-v2-1.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ybc9N-A1OJop"
      },
      "source": [
        "# 🥑 ruDALLE: Generate images from texts.\n",
        "\n",
        "**Link to this notebook - UnenBubb-ruDALLE-generation**-v2.0-dualRAM 🐏🐏\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/UnendingBubbles/generative-notebooks/blob/main/UnenBubb-ruDALL-E-generation.ipynb)\n",
        "\n",
        "♥ Thank you goes to all the creators of ruDALL-E - [GitHub](https://github.com/sberbank-ai/ru-dalle) \n",
        "\n",
        "**Official notebooks - ruDALLE-example-generation.ipynb**\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1wGE-046et27oHvNlBNPH07qrEQNE04PQ?usp=sharing) (for latest updates)\n",
        "\n",
        "**ruDALL-E Malevich (XL) with 3.5GB vRAM!**\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1AoolDYePUpPkRCKIu0cP9zV7lX5QGD3Z?usp=sharing) (for latest updates)\n",
        "\n",
        "\n",
        "helpful subreddits: [r/MachineLearning](https://www.reddit.com/r/MachineLearning/) - [r/MediaSynthesis](https://www.reddit.com/r/MediaSynthesis/) - [r/bigsleep](https://www.reddit.com/r/bigsleep/)\n",
        "\n",
        "[UnendingBubbles](https://github.com/UnendingBubbles) - advanced image grid, live previews, QOL improvments, dual RAM workflows - last updated: 211111 v2.1\n",
        "\n",
        "Instructions at the bottom."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXHbpMh1QlWd"
      },
      "source": [
        "#@markdown #**🧠 Check Resources**\n",
        "import multiprocessing\n",
        "import torch\n",
        "from psutil import virtual_memory\n",
        "!nvidia-smi -L\n",
        "gpu_ram = round(torch.cuda.get_device_properties(0).total_memory / 2**30, 2)\n",
        "print(f'device: {torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\").type} ~ vRAM: {gpu_ram} GB ~ CPU: {multiprocessing.cpu_count()} cores ~ CPU-RAM: {round(virtual_memory().total / 1024**3, 1)} GB ~ PyTorch-version: {torch.__version__} ~ CUDA version: {torch.version.cuda} ~ cuDNN version: {torch.backends.cudnn.version()}')\n",
        "# !nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f__U-Nm7DL7u"
      },
      "source": [
        "#@markdown #**📘 Install ruDALL-E and Setup** (~3min)\n",
        "#@markdown Turn it up to 11 (unrestricted), if you have `High-RAM` Google Colab access.\n",
        "\n",
        "max_vram = 6  #@param {type:\"slider\", min:3.5, max:11.0, step:0.5}\n",
        "ALLOWED_MEMORY = max_vram\n",
        "dwt_mode = \"True = 512x512 (artifacts)\"  #@param [\"False = 256x256 high-quality\", \"True = 512x512>256x256\", \"True = 512x512 (artifacts)\"]\n",
        "#@markdown Turn dwt True for lower RAM to avoid tensor error.\n",
        "\n",
        "from IPython.display import Javascript\n",
        "display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 170})'''))  #limit output height\n",
        "print('install is in progress...')\n",
        "\n",
        "# !pip install rudalle==0.0.1rc6 > /dev/null\n",
        "# !pip install rudalle==0.0.1rc7 > /dev/null\n",
        "# !pip install rudalle==0.0.1rc8 > /dev/null\n",
        "!pip install rudalle==0.0.1rc10 > /dev/null\n",
        "# !pip3 install git+https://github.com/sberbank-ai/ru-dalle.git@master\n",
        "\n",
        "import transformers\n",
        "import more_itertools\n",
        "from tqdm.auto import tqdm\n",
        "from rudalle.pipelines import show, cherry_pick_by_clip\n",
        "from rudalle import get_rudalle_model, get_tokenizer, get_vae, get_ruclip\n",
        "from rudalle.utils import seed_everything, torch_tensors_to_pil_list\n",
        "import multiprocessing\n",
        "import torch\n",
        "from psutil import virtual_memory\n",
        "\n",
        "device = 'cuda'\n",
        "dalle = get_rudalle_model('Malevich', pretrained=True, fp16=True, device=device)\n",
        "tokenizer = get_tokenizer()\n",
        "total_memory = torch.cuda.get_device_properties(0).total_memory / 2**30\n",
        "\n",
        "if ALLOWED_MEMORY < 10.5: # set low-ram workflow\n",
        "    DALLE_BS = int(ALLOWED_MEMORY-2.5)\n",
        "    if torch.__version__ >= '1.8.0':\n",
        "        low_ram_workflow = True\n",
        "        k = ALLOWED_MEMORY/ total_memory\n",
        "        torch.cuda.set_per_process_memory_fraction(k, 0)\n",
        "        print('Allowed GPU RAM:', round(ALLOWED_MEMORY, 2), 'Gb')\n",
        "        print('GPU part', round(k, 4))\n",
        "\n",
        "else: # set high-ram workflow\n",
        "    low_ram_workflow = False\n",
        "    from rudalle.pipelines import generate_images, super_resolution\n",
        "    from rudalle import get_realesrgan\n",
        "    realesrgan = get_realesrgan('x2', device=device) # x2/x4/x8\n",
        "    DALLE_BS = 8\n",
        "\n",
        "# low_ram_workflow = True\n",
        "if dwt_mode == \"False = 256x256 high-quality\":\n",
        "  # vae = get_vae().to(device)  #for default 256x256 in >rc7\n",
        "  if low_ram_workflow == False:\n",
        "    vae = get_vae(dwt=False).to(device)  #for default 256x256 in rc7+\n",
        "  else:\n",
        "    vae = get_vae(dwt=False)\n",
        "if dwt_mode == \"True = 512x512>256x256\" or dwt_mode == \"True = 512x512 (artifacts)\":\n",
        "  if low_ram_workflow == False:\n",
        "    vae = get_vae(dwt=True).to(device)   #for 512x512\n",
        "  else:\n",
        "    vae = get_vae(dwt=True)\n",
        "ruclip, ruclip_processor = get_ruclip('ruclip-vit-base-patch32-v5')\n",
        "if low_ram_workflow == False:\n",
        "  ruclip = ruclip.to(device)\n",
        "\n",
        "\n",
        "!pip install -U deep_translator\n",
        "import time\n",
        "import numpy as np\n",
        "from deep_translator import GoogleTranslator, MyMemoryTranslator\n",
        "# langs_dict = GoogleTranslator.get_supported_languages(as_dict=True)\n",
        "# print(langs_dict)\n",
        "!wget -nc https://www.1001fonts.com/download/font/open-sans.light.ttf -P /content/\n",
        "from PIL import Image\n",
        "\n",
        "def dimr(text, r=165, g=165, b=165):\n",
        "    return \"\\033[38;2;{};{};{}m{} \\033[38;2;255;255;255m\".format(r, g, b, text)\n",
        "def dark(text, r=115, g=115, b=115):\n",
        "    return \"\\033[38;2;{};{};{}m{} \\033[38;2;255;255;255m\".format(r, g, b, text)\n",
        "\n",
        "if low_ram_workflow == True:\n",
        "  def generate_codebooks(text, tokenizer, dalle, top_k, top_p, images_num, image_prompts=None, temperature=1.0, bs=8,\n",
        "                      seed=None, use_cache=True):\n",
        "      vocab_size = dalle.get_param('vocab_size')\n",
        "      text_seq_length = dalle.get_param('text_seq_length')\n",
        "      image_seq_length = dalle.get_param('image_seq_length')\n",
        "      total_seq_length = dalle.get_param('total_seq_length')\n",
        "      device = dalle.get_param('device')\n",
        "      text = text.lower().strip()\n",
        "      input_ids = tokenizer.encode_text(text, text_seq_length=text_seq_length)\n",
        "      codebooks = []\n",
        "      for chunk in more_itertools.chunked(range(images_num), bs):\n",
        "          chunk_bs = len(chunk)\n",
        "          with torch.no_grad():\n",
        "              attention_mask = torch.tril(torch.ones((chunk_bs, 1, total_seq_length, total_seq_length), device=device))\n",
        "              out = input_ids.unsqueeze(0).repeat(chunk_bs, 1).to(device)\n",
        "              has_cache = False\n",
        "              if image_prompts is not None:\n",
        "                  prompts_idx, prompts = image_prompts.image_prompts_idx, image_prompts.image_prompts\n",
        "                  prompts = prompts.repeat(chunk_bs, 1)\n",
        "              for idx in tqdm(range(out.shape[1], total_seq_length)):\n",
        "                  idx -= text_seq_length\n",
        "                  if image_prompts is not None and idx in prompts_idx:\n",
        "                      out = torch.cat((out, prompts[:, idx].unsqueeze(1)), dim=-1)\n",
        "                  else:\n",
        "                      logits, has_cache = dalle(out, attention_mask,\n",
        "                                                has_cache=has_cache, use_cache=use_cache, return_loss=False)\n",
        "                      logits = logits[:, -1, vocab_size:]\n",
        "                      logits /= temperature\n",
        "                      filtered_logits = transformers.top_k_top_p_filtering(logits, top_k=top_k, top_p=top_p)\n",
        "                      probs = torch.nn.functional.softmax(filtered_logits, dim=-1)\n",
        "                      sample = torch.multinomial(probs, 1)\n",
        "                      out = torch.cat((out, sample), dim=-1)\n",
        "              codebooks.append(out[:, -image_seq_length:].cpu())\n",
        "      return codebooks\n",
        "\n",
        "# if you want to save to google drive, run that codeblock (near bottom) before continuing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqfJ1APpafcz"
      },
      "source": [
        "# text = 'a sturdy red chair'\n",
        "# text = 'thinking woman statue logo.'\n",
        "# text = \"'Calm Sailing' a popular classic oil painting of boats on the ocaean.\"\n",
        "# text = \"'Land Ahoy' a popular classic oil painting of a boat on the ocaean at sunset.\"\n",
        "# text = 'Image of the Earth.'\n",
        "# text = 'World Map'\n",
        "# text = \"Jungle Illustration\"\n",
        "# text = \"'Coral Reef with Fish' - digital painting\"\n",
        "# text = \"'Coral Reef with Irridecent Turtle' - digital painting\"\n",
        "# text = 'Пингвины радуются - неизвестная картина Казимира Малевича'\n",
        "# text = \"chrome bar trolley\"  #temp1.05\n",
        "\n",
        "text = \"'Coral Reef with Fish' - digital painting\"\n",
        "\n",
        "original = text\n",
        "tService = GoogleTranslator #GoogleTranslator, MyMemoryTranslator\n",
        "translated = tService(source='en', target='ru').translate(text)\n",
        "rev_translated = tService(source='ru', target='en').translate(translated)\n",
        "print(dimr(f'original: {original}\\ntranslted: {translated}\\nrev-tran: {rev_translated}'))\n",
        "\n",
        "text = translated  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdOYJvwZSB-D"
      },
      "source": [
        "#@markdown #**🏃‍♀️ Run ruDALL-E**\n",
        "# text = \"\"\n",
        "\n",
        "ks = \"4000,1000\" #@param {type:\"string\"}\n",
        "ps = \"0.99, 0.9, 0.7\" #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "temperature =  1.00#@param 1.0 {type:\"number\"}\n",
        "\n",
        "n_bpr =  1#@param {type:\"integer\"}\n",
        "seed =  -1#@param {type:\"integer\"}\n",
        "display_progress = True #@param {type:\"boolean\"}\n",
        "\n",
        "ks = [int(x) for x in ks.split(',')]\n",
        "ps = [float(x) for x in ps.split(',')]\n",
        "\n",
        "##/////////////////////////////////////\n",
        "# custom pk matrix\n",
        "\n",
        "# uncomment any to override above settings\n",
        "\n",
        "# ks = [16384,8192,4096,2048,1024,512,256,128,56,24,12]\n",
        "# ps = [1.4, 1.2, 1.0, 0.9995, 0.995, 0.99, 0.98, 0.95, 0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3]\n",
        "\n",
        "# ks = [128000,32000,16000,8000,4000,2000,1000,600,300,160,80,40,20,10,5]\n",
        "# ps = [99.0, 0.9999, 0.9995, 0.999, 0.99, 0.96, 0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2]\n",
        "\n",
        "ks = [128000,32000,16000,8000,4000,2000,1000,600,300,160,80,40,20,10]\n",
        "ps = [99.0, 0.9999, 0.9995, 0.999, 0.99, 0.96, 0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2]\n",
        "\n",
        "# ks = [128000,32000,8000,4000,1000,600,300,80,10]\n",
        "# ps = [99.0, 0.9999, 0.999, 0.99, 0.96, 0.9, 0.7, 0.3]\n",
        "\n",
        "# ks = [128000,4000,1000,600,80]\n",
        "# ps = [0.9999, 0.999, 0.98, 0.9, 0.65, 0.35]\n",
        "\n",
        "# ks = [8000,3000,600]\n",
        "# ps = [0.9999, 0.9, 0.8]\n",
        "\n",
        "##/////////////////////////////////////\n",
        "# output UI and param setup\n",
        "\n",
        "b_resolves = []\n",
        "for y in range(0, len(ks)):  \n",
        "  for x in range(0, len(ps)):  \n",
        "    t = [(ks[y], ps[x], n_bpr)]\n",
        "    b_resolves.extend(list(t))\n",
        "\n",
        "images_num =  n_bpr\n",
        "total_immys = (len(ps)) * (len(ks)) * images_num\n",
        "timestart = time.strftime('%Y%m%d-%H%M%S')\n",
        "if seed == -1:\n",
        "  seed = np.random.randint(0, 2**31)\n",
        "seed_everything(seed)\n",
        "pil_images = []\n",
        "pil_images2 = []\n",
        "pil_images_debug512 = []\n",
        "scores = []\n",
        "codebooks = []\n",
        "wait_time = 1\n",
        "from IPython.display import Javascript\n",
        "display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 600})'''))  #limit output height\n",
        "print(dark(b_resolves))\n",
        "print(dark(f'seed: {seed}\\ntotal images: {total_immys}'))\n",
        "import time\n",
        "t1 = time.perf_counter()  #start timer\n",
        "print(dimr(f'original: {original}\\ntranslted: {translated}\\nrev-tran: {rev_translated}\\ntext-used: {text}'))\n",
        "numon = 1*images_num\n",
        "\n",
        "##/////////////////////////////////////\n",
        "# batching loop\n",
        "\n",
        "for top_k, top_p, images_num in  b_resolves:\n",
        "\n",
        "    if low_ram_workflow == True: #dwt = True\n",
        "      scodebook = generate_codebooks(text, tokenizer, dalle, top_k=top_k, images_num=images_num, top_p=top_p, bs=DALLE_BS)\n",
        "      for _codebooks in tqdm(torch.cat(scodebook).cpu()):\n",
        "          with torch.no_grad():\n",
        "              images = vae.decode(_codebooks.unsqueeze(0))\n",
        "              spil_image = torch_tensors_to_pil_list(images)\n",
        "              # pil_images_debug512 += spil_image #save 512s to pil_images_debug512\n",
        "              pil_images_debug512.append(spil_image) #save 512s to pil_images_debug512\n",
        "      codebooks += scodebook\n",
        "\n",
        "      if dwt_mode == \"True = 512x512>256x256\":\n",
        "        for num, im in enumerate(spil_image):\n",
        "            im.thumbnail((256,256), resample=Image.LANCZOS, reducing_gap=3)\n",
        "            pil_images.append(im) #save 256s in pil_images\n",
        "      if dwt_mode == \"True = 512x512 (artifacts)\":\n",
        "        for num, im in enumerate(spil_image):\n",
        "            pil_images.append(im) #save 512s in pil_images\n",
        "\n",
        "      if display_progress == True:\n",
        "        cheapeta = format((total_immys-numon)*(72/60), \".3g\")  #put your time to complete one img here (seconds/60)\n",
        "        print(dark(f'{top_k} {top_p}   ~  {numon}/{total_immys}  ~   eta: {cheapeta} min'))\n",
        "        show(pil_images, len(ps)*n_bpr, size=6)  #change size of output images here (network intensive if too big)\n",
        "        numon += 1 * images_num\n",
        "\n",
        "    else: #dwt = False\n",
        "      _pil_images, _scores = generate_images(text, tokenizer, dalle, vae, top_k=top_k, top_p=top_p, images_num=images_num, temperature=temperature)\n",
        "      pil_images += _pil_images\n",
        "      scores += _scores\n",
        "      if display_progress == True:\n",
        "        cheapeta = format((total_immys-numon)*(50/60), \".3g\")  #put your time to complete one img here (seconds/60)\n",
        "        print(dark(f'{top_k} {top_p}   ~  {numon}/{total_immys}  ~   eta: {cheapeta} min'))\n",
        "        show(pil_images, len(ps)*n_bpr, size=6)  #change size of output images here (network intensive if too big)\n",
        "        numon += 1 * images_num\n",
        "\n",
        "\n",
        "t2 = time.perf_counter()  #end timer\n",
        "wait_time = t2-t1\n",
        "# print('time taken to run: ',format(wait_time, \".5g\"))\n",
        "print(dark(f'\\nimages made: {len(pil_images)}'))\n",
        "print(dark(f'time taken: {time.strftime(\"%M:%S\",time.gmtime(int(wait_time)))}'))\n",
        "print(dark(f'time per image: {time.strftime(\"%M:%S\",time.gmtime(int(wait_time)/len(pil_images)))}'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-sfSSBzQpar"
      },
      "source": [
        "#@title 🌟 Upscale `pil_images` with ruRealEsrgan to `sr_images`\n",
        "# upscale not yet avaliable (simultaniously) for low-ram\n",
        "generate_sr = False #@param {type:\"boolean\"}\n",
        "rurealesrgan_multiplier = \"x2\" #@param [\"x2\",\"x4\",\"x8\"]\n",
        "if generate_sr == True: \n",
        "  realesrgan = get_realesrgan(rurealesrgan_multiplier, device=device)\n",
        "  sr_images = super_resolution(pil_images, realesrgan)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxjufSs_aoxi"
      },
      "source": [
        "#@markdown #**🔳 Create a Grid of Images**\n",
        "\n",
        "import time\n",
        "import PIL, os, glob\n",
        "from IPython.display import Image\n",
        "from PIL import Image, ImageEnhance\n",
        "from PIL import ImageDraw\n",
        "from math import ceil, floor, trunc\n",
        "from google.colab import files\n",
        "\n",
        "generate_grid = True #@param {type:\"boolean\"}\n",
        "draw_text = True #@param {type:\"boolean\"}\n",
        "draw_pk_text = True #@param {type:\"boolean\"}\n",
        "filetype_out = \"png\" #@param [\"jpg\", \"png\"]\n",
        "img_source = \"pil_images\" #@param [\"pil_images\", \"sr_images\", \"top_images\", \"pil_images_debug512\"]\n",
        "# filetype_in = \"png\" #@param [\"jpg\", \"png\"]\n",
        "destination = \"/content/drive/MyDrive/happyml/ruDALL-E-rc10\" #@param {type:\"string\"}\n",
        "# text is experimental and in need of more robust code\n",
        "author_text = \"github.com/UnendingBubbles\" #@param {type:\"string\"}\n",
        "max_imgs =  199 #@param {type:\"number\"}\n",
        "\n",
        "# destination = \"/content/grided\"\n",
        "destination_presharp = \"/content/finals-sharp\"\n",
        "\n",
        "#@markdown Enable `pixel_perfect` to disable resizing of images. Must be disabled to use `frame_width`, a custom final px width. Even with `pixel_perfect` enabled, images that are different aspect ratio or larger size from the first, will be resized to fit. Must be enabled to `draw_text`.\n",
        "pixel_perfect = True #@param {type:\"boolean\"}\n",
        "#@markdown Disable `draw_pk_text` to use `images_per_row`.\n",
        "images_per_row = 6 #@param {type:\"integer\"}\n",
        "frame_width =  1200 #@param {type:\"number\"}\n",
        "padding =   18#@param {type:\"number\"}\n",
        "border =  42#@param {type:\"number\"}\n",
        "bgRed = 30 #@param {type:\"number\"} \n",
        "bgGreen = 30 #@param {type:\"number\"} \n",
        "bgBlue =  30 #@param {type:\"number\"} \n",
        "\n",
        "download_when_complete = True  #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown ___\n",
        "#@markdown **Sharpening:** might only be useful if images are generated from non-sharpend datasets, very downscaled, or viewed on an imperfect medium. Sharpening is always a destructive process, but so is looking at a computer monitor.\n",
        "\n",
        "#@markdown (Values above 1.00 sharpen, below 1.00 to blur.)\n",
        "\n",
        "#@markdown **Pre-sharpening** to be applied to original input images, durring processing, before images are put into a grid.\n",
        "\n",
        "apply_pre_sharp = False #@param {type:\"boolean\"}\n",
        "#@markdown  (Values of 1.10-1.50 when downscaling. Less if `pixel_perfect` enabled)\n",
        "pre_sharpening =  1.6#@param {type:\"number\"}  \n",
        "#@markdown  Save all those pre-sharpened originals in `finals-sharp` folder?\n",
        "save_pre_sharps = False #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown If you can notice sharpening without zooming to 1:1 pixels, it's probably too much sharpening. 🤷‍♀️ Windows tip: press Ctrl+1 in windows-photos-app to view at 100% scale, after opening.\n",
        "\n",
        "##/////////////////////////////////////\n",
        "# setup params\n",
        "\n",
        "timegrid = time.strftime('%H%M%S')\n",
        "reso_crp = len(ps)+1 #max length of info-text b_resolve list (any number)\n",
        "reso_cropped = (str(b_resolves[:reso_crp]) + '...') if len(b_resolves) > reso_crp else b_resolves\n",
        "\n",
        "if draw_text == True:\n",
        "  pad_bottom =  30\n",
        "else:\n",
        "  pad_bottom =  0\n",
        "\n",
        "if draw_pk_text == True:\n",
        "  images_per_row = len(ps)*n_bpr  #override\n",
        "\n",
        "text_safe = (f'{rev_translated[:15]}')\n",
        "\n",
        "# img_source = globals()[img_source] #convert string to loaded images\n",
        "img_source = eval(img_source) #convert string to loaded images (less safe, but handles index)\n",
        "# pil_tup = tuple(img_source) #make list of PIL imgs into enumeration-compliant tupple\n",
        "# images = glob.glob(\"/content/finll/*.*\")\n",
        "# images = pil_images\n",
        "# images = sr_images\n",
        "# images = pil_tup\n",
        "images = img_source\n",
        "images = images[:max_imgs]\n",
        "\n",
        "os.makedirs(f'{destination}', exist_ok=True)\n",
        "full_destination = f'{destination}/{timestart}-{text_safe}-{timegrid}-{str(len(images))}up.{filetype_out}'\n",
        "\n",
        "##/////////////////////////////////////\n",
        "# image placement\n",
        "\n",
        "def gridcreator(destination, frame_width):\n",
        "\n",
        "  # images = glob.glob(\"/content/finals/*.*\")\n",
        "  # images = pil_tup\n",
        "  # images = pil_images\n",
        "  # images = sr_images\n",
        "  images = img_source\n",
        "  images = images[:max_imgs]\n",
        "  # images.sort(key=os.path.getctime)      #sort files by date\n",
        "\n",
        "  img_width, img_height = images[0].size\n",
        "  sf = (frame_width-(images_per_row-1)*padding)/(images_per_row*img_width)     #scaling factor\n",
        "  scaled_img_width = ceil(img_width*sf)                  \n",
        "  scaled_img_height = ceil(img_height*sf) + padding\n",
        "  number_of_rows = ceil(len(images)/images_per_row)\n",
        "\n",
        "  if pixel_perfect == True:\n",
        "    scaled_img_width = img_width\n",
        "    scaled_img_height = img_height + padding\n",
        "    frame_width = images_per_row * (img_width) + ((images_per_row-1) * padding)\n",
        "\n",
        "  frame_height = ceil(scaled_img_height*number_of_rows)\n",
        "  new_im = Image.new('RGB', (frame_width+border*2, frame_height+border*2-padding+pad_bottom), (bgRed, bgGreen, bgBlue)) \n",
        "\n",
        "  i,j=0,0\n",
        "  for num, im in enumerate(images):\n",
        "      if num%images_per_row==0:\n",
        "          i=0\n",
        "      # im = Image.open(im) if using saved images, load them as PIL\n",
        "      if apply_pre_sharp == 1:\n",
        "        enhancer = ImageEnhance.Sharpness(im)\n",
        "        im = enhancer.enhance(pre_sharpening)\n",
        "        if save_pre_sharps == 1:\n",
        "          os.makedirs(f'{destination_presharp}', exist_ok=True)\n",
        "          if filetype_out == \"jpg\":\n",
        "            new_im.save(f'{destination_presharp}/{text_safe}-{i}', \"JPEG\", quality=94, optimize=True, progressive=True)\n",
        "          if filetype_out == \"png\":\n",
        "            new_im.save(f'{destination_presharp}/{text_safe}-{i}', \"PNG\", quality=87, optimize=True, progressive=True)\n",
        "      im.thumbnail((scaled_img_width,scaled_img_height), resample=Image.LANCZOS, reducing_gap=3)\n",
        "      y_cord = (j//images_per_row)*scaled_img_height\n",
        "      new_im.paste(im, (i+border,y_cord+border))\n",
        "      #print(i, y_cord)\n",
        "      i=(i+scaled_img_width)+padding\n",
        "      j+=1\n",
        "\n",
        "##/////////////////////////////////////\n",
        "# draw text\n",
        "\n",
        "  if apply_pre_sharp == True:\n",
        "    sharp_info =  f' - pre-sharp={apply_pre_sharp}:{pre_sharpening}'\n",
        "  else:\n",
        "    sharp_info = \"\"\n",
        "\n",
        "  if draw_text == True:\n",
        "    mygrey = 75\n",
        "    mygrey2 = 100\n",
        "    mycolr = (mygrey, mygrey, mygrey)\n",
        "    mycolr2 = (mygrey2, mygrey2, mygrey2)\n",
        "    from PIL import ImageFont\n",
        "    # !wget -nc https://www.1001fonts.com/download/font/open-sans.light.ttf -P /content/\n",
        "    font = ImageFont.truetype(r'/content/open-sans.light.ttf', 11)\n",
        "    draw = ImageDraw.Draw(new_im)\n",
        "    # draw.text((border+1, frame_height+border+(number_of_rows-1)*padding-40),f'{original} - {translated}',mycolr,font=font)\n",
        "    # draw.text((border+1, frame_height+border+(number_of_rows-1)*padding-20),f'utc{timestart} - s{seed} - {format(wait_time/60, \".3g\")}min - temp{temperature} - {reso_cropped}{sharp_info} - ruDALL-E-rc10 - {author_text}',mycolr,font=font)\n",
        "    draw.text((border+1, frame_height+border-5),f'{original} - {translated}',mycolr,font=font)\n",
        "    draw.text((border+1, frame_height+border+13),f'utc{timestart} - s{seed} - {format(wait_time/60, \".3g\")}min - temp{temperature} - {reso_cropped}{sharp_info} - ruDALL-E-rc10 - {author_text}',mycolr,font=font)\n",
        "\n",
        "    if draw_pk_text == True:\n",
        "      draw.text((border+1,border-30),f'[ k - p ] grid for ruDALL-E',mycolr2,font=font) \n",
        "      for y in range(0, number_of_rows): \n",
        "        for x in range(0, len(ps)): \n",
        "          draw.text(((scaled_img_width+padding)*x*n_bpr+border,(scaled_img_height)*y-15+border),f'{ks[y]} - {ps[x]}',mycolr2,font=font)\n",
        "\n",
        "##/////////////////////////////////////\n",
        "# saving\n",
        "\n",
        "  if filetype_out == \"jpg\":\n",
        "    new_im.save(full_destination, \"JPEG\", quality=94, optimize=True, progressive=True)\n",
        "  if filetype_out == \"png\":\n",
        "    new_im.save(full_destination, \"PNG\", quality=87, optimize=True, progressive=True)\n",
        "  if download_when_complete == True:\n",
        "    print('download requet sent...')\n",
        "    files.download(full_destination)\n",
        "\n",
        "  print(f\"{full_destination} - {os.path.getsize(full_destination)/1048576:.3f} MB\")\n",
        "\n",
        "##/////////////////////////////////////\n",
        "# generate\n",
        "\n",
        "try:\n",
        "  if generate_grid == True:\n",
        "    #print('generating grid...')\n",
        "    gridcreator(destination, frame_width)  #it gets upset if you dont pass these variables for some reason\n",
        "    #Image(full_destination)\n",
        "  else:\n",
        "    print('check \"generate_grid\" to run this feature.')\n",
        "except KeyboardInterrupt:  #ability to stop without unresponsive error\n",
        "  pass\n",
        "\n",
        "print(text)\n",
        "full_destination = f'{destination}/{text_safe}-{str(len(images))}up.{filetype_out}'\n",
        "print(\"\\n\")\n",
        "# Warning: Colab session may softcrash if trying to display very high-res files. It sends uncompressed PNG to browser no matter the input. Uncomment below for preview (if you dare).\n",
        "# from IPython.display import Image \n",
        "# Image(full_destination)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtkFODCknMj-"
      },
      "source": [
        "#@title 💾 Export `pil_images` as PNG images\n",
        "from IPython.display import Javascript\n",
        "display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 100})'''))  #limit output height\n",
        "from google.colab import files\n",
        "import os\n",
        "save_out = True #@param {type:\"boolean\"}\n",
        "zip_out = True #@param {type:\"boolean\"}\n",
        "out_destination = \"/content/outs\" #@param {type:\"string\"}\n",
        "zip_destination = \"/content/zips\" #@param {type:\"string\"}\n",
        "quality = 87 #@param {type:\"integer\"}\n",
        "download_zip = True  #@param {type:\"boolean\"}\n",
        "if save_out == True:\n",
        "  timesave = time.strftime('%H%M%S')\n",
        "  text_safe = (f'{rev_translated[:15]}')\n",
        "  text_safe = text_safe.replace(\" \", \"-\") #remove space\n",
        "  text_safe = text_safe.replace(\"'\", \"-\") #remove special\n",
        "  os.makedirs(f'{out_destination}', exist_ok=True)\n",
        "  for i in range(0, len(pil_images)):\n",
        "    im = pil_images[i]\n",
        "    im.save(f'{out_destination}/{timestart}-{text_safe}-{timesave}-{i}.png', \"PNG\", quality=quality, optimize=True, progressive=True)\n",
        "if zip_out == True:\n",
        "    zip_place = f'{zip_destination}-{timestart}-{text_safe}-{timesave}.zip'\n",
        "    !zip -r $zip_place $out_destination\n",
        "    from google.colab import files\n",
        "    files.download(zip_place)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BbZVDyUoKIu"
      },
      "source": [
        "#@title 💾 Zip a Folder\n",
        "from IPython.display import Javascript\n",
        "display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 100})'''))  #limit output height\n",
        "from google.colab import files\n",
        "import os\n",
        "zip_folder = False #@param {type:\"boolean\"}\n",
        "folder_to_zip = \"/content/grided\" #@param {type:\"string\"}\n",
        "download_zip = False  #@param {type:\"boolean\"}\n",
        "if zip_folder == True:\n",
        "    zip_place = f'{zip_destination}-{timestart}-{timesave}.zip'\n",
        "    !zip -r $folder_to_zip $out_destination\n",
        "    from google.colab import files\n",
        "    files.download(zip_place)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMIYuKighRQR"
      },
      "source": [
        "#@title 💾 Mount Google Drive (optional)\n",
        "#@markdown To connect Google Drive, set `root_path` to the relative drive folder path you want outputs to be saved to if you already made a directory, then execute this cell.\n",
        "mount_gdrive = False #@param {type:\"boolean\"}\n",
        "if mount_gdrive == True: \n",
        "  import os\n",
        "  root_path = 'happyml/ruDALL-E-rc10' #@param {type: \"string\"}\n",
        "  gdrive_root_path = \"\"\n",
        "  if len(root_path) > 0:\n",
        "      gdrive_root_path = '/content/drive/MyDrive/' + root_path\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "\n",
        "  if len(gdrive_root_path) > 0:\n",
        "      # os.chdir(gdrive_root_path) # Changes directory to absolute root path\n",
        "      print(f'gdrive_root_path = {gdrive_root_path}')\n",
        "\n",
        "#@markdown When asked, in output below, paste your code and hit Enter.\n",
        "\n",
        "#@markdown Paste this directory into the \"destination\" of the Grid Generator."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEGx8sK0QwDp"
      },
      "source": [
        "#@title 🍒Cherry-pick `pil_images` with ruCLIP to `top_images` \n",
        "pick_cherries = False #@param {type:\"boolean\"}\n",
        "n_cherries = 6 #@param {type:\"integer\"}\n",
        "if pick_cherries == True: \n",
        "  top_images, clip_scores = cherry_pick_by_clip(pil_images, text, ruclip, ruclip_processor, device=device, count=n_cherries)\n",
        "  show(top_images, 4)  #4 columns wide"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6KBGL0GBLGW"
      },
      "source": [
        "#@title 🌟 Upscale `top_images` with ruRealEsrgan to `sr_images`\n",
        "generate_sr = False #@param {type:\"boolean\"}\n",
        "rurealesrgan_multiplier = \"x2\" #@param [\"x2\",\"x4\",\"x8\"]\n",
        "if generate_sr == True: \n",
        "  realesrgan = get_realesrgan(rurealesrgan_multiplier, device=device)\n",
        "  sr_images = super_resolution(top_images, realesrgan)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saGz27MUcDOd"
      },
      "source": [
        "#@title Display SR images\n",
        "# show(sr_images, 3, save_dir='/content/sr')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UA4sY-ZCSCA7"
      },
      "source": [
        "#@title Display images in sorted order\n",
        "# show([pil_image for pil_image, score in sorted(zip(pil_images, scores), key=lambda x: -x[1])] , 6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWABNaYstOfi"
      },
      "source": [
        "---\n",
        "Create an editable copy for yourself with `File > Save a Copy in Drive`.  \n",
        "To Run this Notebook, select `Runtime` in the top toolbar menu, then `Run All (Ctrl+F9)`.   \n",
        "To Run/Stop individual code blocks: Click the `▶` or `⏹` button in the upper-left of each code block. It will appear when hovering. Some codeblocks require a `☑` checked to run (Run-All compliant).\n",
        "\n",
        "---\n",
        "If you lose connection, or Colab is acting weird, you can save your settings with `File > Download > .ipynb`.  \n",
        "Then, refresh with `F5`. If that does not work, try `Runtime > Restart Runtime` or `Factory Restart Runtime`.  \n",
        "\n",
        "---\n",
        "You can doublecheck Colab settings with `Runtime > Change Runstime Type`:  \n",
        "* `Hardware Accelerator` must be `GPU`.\n",
        "* `Runtime Shape` should be `High-RAM` if avaliable.\n",
        "* `☑ Omit code cell output when saving` should be checked so that your `.ipynb` files do not grow massive in size.\n",
        "\n",
        "---\n",
        "This notebook can output `error` or `warning`, but if it continues, it's okay.  \n",
        "If CUDA runs out of memory, try a factory restart with all default settings."
      ]
    }
  ]
}
